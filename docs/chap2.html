<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction aux séries temporelles - 3&nbsp; Modélisation aléatoire des séries temporelles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chap3.html" rel="next">
<link href="./chap1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chap2.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modélisation aléatoire des séries temporelles</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction aux séries temporelles</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Préface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Tendances et saisonnalités</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modélisation aléatoire des séries temporelles</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Statistique des processus stationnaires du second ordre</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chap4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Les modèles ARMA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#processus-stochastiques" id="toc-processus-stochastiques" class="nav-link active" data-scroll-target="#processus-stochastiques"><span class="header-section-number">3.1</span> Processus stochastiques</a>
  <ul class="collapse">
  <li><a href="#définition" id="toc-définition" class="nav-link" data-scroll-target="#définition"><span class="header-section-number">3.1.1</span> Définition</a></li>
  <li><a href="#premiers-exemples-de-processus" id="toc-premiers-exemples-de-processus" class="nav-link" data-scroll-target="#premiers-exemples-de-processus"><span class="header-section-number">3.1.2</span> Premiers exemples de processus</a></li>
  </ul></li>
  <li><a href="#rappels-sur-lespace-l2-et-les-processus-du-second-ordre" id="toc-rappels-sur-lespace-l2-et-les-processus-du-second-ordre" class="nav-link" data-scroll-target="#rappels-sur-lespace-l2-et-les-processus-du-second-ordre"><span class="header-section-number">3.2</span> Rappels sur l’espace <span class="math inline">\(L^2\)</span> et les processus du second ordre</a>
  <ul class="collapse">
  <li><a href="#espace-l2" id="toc-espace-l2" class="nav-link" data-scroll-target="#espace-l2"><span class="header-section-number">3.2.1</span> Espace <span class="math inline">\(L^2\)</span></a></li>
  <li><a href="#convergence-dans-l2" id="toc-convergence-dans-l2" class="nav-link" data-scroll-target="#convergence-dans-l2"><span class="header-section-number">3.2.2</span> Convergence dans <span class="math inline">\(L^2\)</span></a></li>
  <li><a href="#projection-orthogonale" id="toc-projection-orthogonale" class="nav-link" data-scroll-target="#projection-orthogonale"><span class="header-section-number">3.2.3</span> Projection orthogonale</a></li>
  </ul></li>
  <li><a href="#processus-stationnaires" id="toc-processus-stationnaires" class="nav-link" data-scroll-target="#processus-stationnaires"><span class="header-section-number">3.3</span> Processus stationnaires</a></li>
  <li><a href="#fonctions-dautocovariance-et-dautocorrélation" id="toc-fonctions-dautocovariance-et-dautocorrélation" class="nav-link" data-scroll-target="#fonctions-dautocovariance-et-dautocorrélation"><span class="header-section-number">3.4</span> Fonctions d’autocovariance et d’autocorrélation</a>
  <ul class="collapse">
  <li><a href="#fonction-dautocovariance-acvf" id="toc-fonction-dautocovariance-acvf" class="nav-link" data-scroll-target="#fonction-dautocovariance-acvf"><span class="header-section-number">3.4.1</span> Fonction d’autocovariance (ACVF)</a></li>
  <li><a href="#fonction-dautocorrélation-acf" id="toc-fonction-dautocorrélation-acf" class="nav-link" data-scroll-target="#fonction-dautocorrélation-acf"><span class="header-section-number">3.4.2</span> Fonction d’autocorrélation (ACF)</a></li>
  <li><a href="#exemples" id="toc-exemples" class="nav-link" data-scroll-target="#exemples"><span class="header-section-number">3.4.3</span> Exemples</a></li>
  <li><a href="#cns-pour-une-fonction-dautocovariance" id="toc-cns-pour-une-fonction-dautocovariance" class="nav-link" data-scroll-target="#cns-pour-une-fonction-dautocovariance"><span class="header-section-number">3.4.4</span> CNS pour une fonction d’autocovariance</a></li>
  <li><a href="#matrice-dautocorrélation" id="toc-matrice-dautocorrélation" class="nav-link" data-scroll-target="#matrice-dautocorrélation"><span class="header-section-number">3.4.5</span> Matrice d’autocorrélation</a></li>
  <li><a href="#premiers-pas-vers-les-processus-arma" id="toc-premiers-pas-vers-les-processus-arma" class="nav-link" data-scroll-target="#premiers-pas-vers-les-processus-arma"><span class="header-section-number">3.4.6</span> Premiers pas vers les processus ARMA</a></li>
  </ul></li>
  <li><a href="#densité-spectrale" id="toc-densité-spectrale" class="nav-link" data-scroll-target="#densité-spectrale"><span class="header-section-number">3.5</span> Densité spectrale</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modélisation aléatoire des séries temporelles</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><span class="math display">\[
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\C}{\text{Cov}}
\newcommand{\V}{\mathrm{Var}}
\]</span></p>
<!----------------------------------->
<p>Dans la suite du cours, nous allons aller vers une modélisation aléatoire des séries temporelles. Une série temporelle sera vue comme une réalisation d’un processus stochastique avec certaines propriétés. Ce chapitre pose donc les définitions et propriétés importantes pour la suite autour des notions de processus du second ordre et de processus stationnaire.</p>
<section id="processus-stochastiques" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="processus-stochastiques"><span class="header-section-number">3.1</span> Processus stochastiques</h2>
<section id="définition" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="définition"><span class="header-section-number">3.1.1</span> Définition</h3>
<div id="def-stoch" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 </strong></span>On appelle <span style="color:blue;"><strong>processus stochastique</strong></span> toute famille de variables aléatoires (v.a.) <span class="math inline">\((X_t)_{t\in T}\)</span> d’un espace probabilisé <span class="math inline">\((\Omega,\mathcal A, P)\)</span> vers un espace probabilisable <span class="math inline">\((E, \mathcal E)\)</span> <span class="math display">\[
\forall t\in T,\ X_t\text{ est une v.a. de } (\Omega,\mathcal A, P) \text{ vers }(E, \mathcal E).
\]</span></p>
<p>L’ensemble <span class="math inline">\(T\)</span> est appelé <span style="color:blue;"><strong>espace des temps</strong></span> et <span class="math inline">\(E\)</span> <span style="color:blue;"><strong>espace des états</strong></span>. Chacun de ces espaces peut être discret ou continu. <br></p>
<p>Pour <span class="math inline">\(\omega\in \Omega\)</span>, on appelle <span style="color:blue;"><strong>trajectoire du processus</strong></span> la fonction (déterministe) : <span class="math display">\[
t\mapsto X_t(\omega).
\]</span></p>
</div>
<p><br></p>
<p>Dans ce cours, les séries temporelles sont vues comme des réalisations d’un processus stochastique à <strong>espace des temps discret</strong>, à savoir <span class="math inline">\(T=\N\)</span>, ou pour des raisons mathématiques <span class="math inline">\(T=\Z\)</span>. Elles ne sont observées que sur un intervalle de temps fini (on observe qu’une partie de la trajectoire du processus). En général, on considère <span class="math inline">\(E=\R\)</span> comme espace des états et la tribu borélienne <span class="math inline">\(\mathcal E=\mathcal B_{\R}\)</span>.</p>
<p>Dans ce cours on n’abordera pas les <strong>processus spatiaux</strong> (<span class="math inline">\(\mbox{dim}(T)\geq 2\)</span>), ni les séries temporelles <strong>multivariées</strong> (<span class="math inline">\(E=\R^n\)</span>).</p>
</section>
<section id="premiers-exemples-de-processus" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="premiers-exemples-de-processus"><span class="header-section-number">3.1.2</span> Premiers exemples de processus</h3>
<section id="bruit-blanc-fort-faible" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="bruit-blanc-fort-faible"><span class="header-section-number">3.1.2.1</span> Bruit blanc fort / faible</h4>
<div id="def-bbF" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2 </strong></span>Un <span style="color:blue;"><strong>bruit blanc fort</strong></span> est une suite de variables indépendantes et identiquement distribuées (i.i.d.) <span class="math inline">\((X_t)_{t\in T}\)</span> centrées et de variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>On note <span class="math inline">\((X_t)_{t\in T} \sim \text{IID}(0,\sigma^2)\)</span>.</p>
</div>
<p><br> Dans le cas d’un bruit blanc fort, il n’y a aucun dépendance entre les observations. En particulier, la connaissance de <span class="math inline">\(X_1,\ldots,X_n\)</span> n’informe en rien sur la valeur (future) de <span class="math inline">\(X_{n+h}\)</span>. Si la loi commune des v.a. est gaussienne, on parle de bruit blanc gaussien (la <a href="#fig-bbN">Figure&nbsp;<span>3.1</span></a> donne un exemple de simulation d’une partie de trajectoire).</p>
<div id="def-bbG" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3 </strong></span>On appelle <span style="color:blue;"><strong>bruit blanc gaussien</strong></span>, tout bruit blanc fort pour lequel la loi commune des v.a.r. <span class="math inline">\((X_t)_{t\in T}\)</span> est une <span class="math inline">\(\mathcal N(0,\sigma^2)\)</span>.</p>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-bbN" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-bbN-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3.1: Trajectoire d’un bruit blanc gaussien <span class="math inline">\(\mathcal N(0,1)\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>L’hypothèse d’i.i.d est très forte, on peut considérer une version faible d’un bruit blanc en ne demandant que la non-corrélation.</p>
<div id="def-bb" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.4 </strong></span>On appelle <span style="color:blue;"><strong>bruit blanc faible</strong></span> toute suite de v.a.r. <span class="math inline">\((X_t)_{t\in T}\)</span></p>
<ul>
<li>centrées et de variance <span class="math inline">\(\sigma^2\)</span></li>
<li><span style="color:blue;"><strong>non corrélées</strong></span></li>
</ul>
<p>On note <span class="math inline">\((X_t)_{t\in T} \sim \text{WN}(0,\sigma^2)\)</span></p>
</div>
<p><br> En tant que tels, ces processus n’ont pas d’intéret direct pour un objectif de prévision. Mais nous verrons qu’ils jouent un rôle important dans la modélisation de séries temporelles plus complexes.</p>
</section>
<section id="marche-aléatoire" class="level4" data-number="3.1.2.2">
<h4 data-number="3.1.2.2" class="anchored" data-anchor-id="marche-aléatoire"><span class="header-section-number">3.1.2.2</span> Marche aléatoire</h4>
<p>A partir d’un bruit blanc fort, on peut construire une marche aléatoire.</p>
<div id="def-MarcheA" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.5 </strong></span>Une <span style="color:blue;"><strong>marche aléatoire</strong></span> <span class="math inline">\((S_t)_{t\in \mathbb N}\)</span> est obtenue par <span class="math display">\[
S_t=X_1+\ldots+X_t,\ \ \forall t\in \mathbb{N}
\]</span> où <span class="math inline">\((X_t)_{t\in \mathbb N}\)</span> est un bruit blanc fort.</p>
<p>Si ce dernier est un processus binaire (<span class="math inline">\(\mathbb{P}(X_t=1)=\mathbb{P}(X_t=-1)=\frac 1 2\)</span>) alors la marche aléatoire <span class="math inline">\((S_t)_{t\in \mathbb N}\)</span> est dite <strong>symétrique simple</strong>.</p>
</div>
<p><br> La <a href="#fig-exmarchealea">Figure&nbsp;<span>3.2</span></a> montre des exemples de trajectoires de marches aléatoires.</p>
<div id="fig-exmarchealea" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exmarchealea-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exmarchealea-1.png" class="img-fluid figure-img" data-ref-parent="fig-exmarchealea" width="672"></p>
<figcaption class="figure-caption">(a) … symétrique simple</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exmarchealea-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exmarchealea-2.png" class="img-fluid figure-img" data-ref-parent="fig-exmarchealea" width="672"></p>
<figcaption class="figure-caption">(b) … à partir d’un bruit blanc gaussien de variance <span class="math inline">\(0.5^2\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.2: Trajectoire d’une marche aléatoire …</figcaption><p></p>
</figure>
</div>
</section>
<section id="processus-gaussien" class="level4" data-number="3.1.2.3">
<h4 data-number="3.1.2.3" class="anchored" data-anchor-id="processus-gaussien"><span class="header-section-number">3.1.2.3</span> Processus gaussien</h4>
<div id="def-ProcG" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.6 </strong></span>Un <span style="color:blue;"><strong>processus gaussien</strong></span> à temps discret <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est une série temporelle telle que la loi de n’importe quel vecteur extrait est gaussien <span class="math display">\[
\forall n\in \N^*, \forall (t_1,\ldots,t_n)\in \Z^n : (X_{t_1},\ldots,X_{t_n}) \text{ est un vecteur gaussien.}
\]</span></p>
</div>
<p><br> Un bruit blanc gaussien est donc un processus gaussien.</p>
</section>
<section id="processus-ma1" class="level4" data-number="3.1.2.4">
<h4 data-number="3.1.2.4" class="anchored" data-anchor-id="processus-ma1"><span class="header-section-number">3.1.2.4</span> Processus MA(1)</h4>
<div id="def-MA1" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.7 </strong></span>On appelle <span style="color:blue;"><strong>processus moyenne mobile d’ordre 1</strong></span> toute série temporelle <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> définie par : <span class="math display">\[
X_t=\varepsilon_t+\theta\ \varepsilon_{t-1},\ \forall t\in \mathbb Z,
\]</span> où <span class="math inline">\((\varepsilon_t)_{t\in \mathbb Z}\sim \text{WN}(0,\sigma^2)\)</span> et <span class="math inline">\(\theta \in \mathbb R\)</span>.</p>
<p>On note <span class="math inline">\((X_t)_{t\in \mathbb Z}\sim\)</span>MA(1).</p>
</div>
<p><br></p>
<p>La <a href="#fig-exMA1">Figure&nbsp;<span>3.3</span></a> donne des exemples de trajectoires de processus MA(1). Cette notion de processus moyenne mobile sera étendue à des ordres supérieurs et fera l’objet d’une étude approfondie dans la <a href="chap4.html#sec-chap4MA"><span>Section&nbsp;5.3</span></a> du <a href="chap4.html"><span>Chapter&nbsp;5</span></a>.</p>
<div id="fig-exMA1" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exMA1-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exMA1-1.png" class="img-fluid figure-img" data-ref-parent="fig-exMA1" width="672"></p>
<figcaption class="figure-caption">(a) pour <span class="math inline">\(\theta=0.2\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exMA1-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exMA1-2.png" class="img-fluid figure-img" data-ref-parent="fig-exMA1" width="672"></p>
<figcaption class="figure-caption">(b) pour <span class="math inline">\(\theta=1\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.3: Exemple de trajectoires d’un processus MA(1)</figcaption><p></p>
</figure>
</div>
</section>
<section id="processus-ar1" class="level4" data-number="3.1.2.5">
<h4 data-number="3.1.2.5" class="anchored" data-anchor-id="processus-ar1"><span class="header-section-number">3.1.2.5</span> Processus AR(1)</h4>
<div id="def-AR1" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.8 </strong></span>On appelle <span style="color:blue;"><strong>processus autorégressif d’ordre 1</strong></span> toute série temporelle <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> définie par : <span class="math display">\[
X_t=\varphi_0+\varphi_1X_{t-1}+ \varepsilon_t,\ \forall t\in \mathbb Z,
\]</span> où <span class="math inline">\((\varepsilon_t)_{t\in \mathbb Z}\sim \text{WN}(0,\sigma^2)\)</span> et <span class="math inline">\((\varphi_0,\varphi_1) \in \mathbb R^2\)</span>.</p>
<p>On note <span class="math inline">\((X_t)_{t\in \mathbb Z}\sim\)</span>AR(1).</p>
</div>
<p><br></p>
<p>La <a href="#fig-exAR1">Figure&nbsp;<span>3.4</span></a> donne des exemples de trajectoires de processus AR(1). Cette notion de processus autorégressif sera étendue à des ordres supérieurs et fera l’objet d’une étude approfondie dans la <a href="chap4.html#sec-chap4AR"><span>Section&nbsp;5.2</span></a> du <a href="chap4.html"><span>Chapter&nbsp;5</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-exAR1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exAR1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3.4: Exemple de trajectoire d’un processus AR(1)</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="rappels-sur-lespace-l2-et-les-processus-du-second-ordre" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="rappels-sur-lespace-l2-et-les-processus-du-second-ordre"><span class="header-section-number">3.2</span> Rappels sur l’espace <span class="math inline">\(L^2\)</span> et les processus du second ordre</h2>
<section id="espace-l2" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="espace-l2"><span class="header-section-number">3.2.1</span> Espace <span class="math inline">\(L^2\)</span></h3>
<div id="def-L2" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.9 </strong></span>On dit qu’une v.a.r. <span class="math inline">\(X\)</span> est dans l’espace <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> si l’on a <span class="math inline">\(\E[X^2]&lt;+\infty.\)</span></p>
<p>Cet espace <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> est un espace de Hilbert muni du produit scalaire <span class="math display">\[
\langle X,Y\rangle_{L^2}=\E[XY]
\]</span> et de la norme <span class="math display">\[
||X||_{L^2}=\sqrt{\E[X^2]}.
\]</span></p>
</div>
<p><br></p>
<p>Dans cet espace <span class="math inline">\(L^2\)</span>, on a donc que <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont orthogonaux (<span class="math inline">\(X\perp Y\)</span>) si <span class="math inline">\(\E[XY]=0\)</span>. Si de plus les v.a. <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont centrées, cela revient à avoir <span class="math inline">\(\C(X,Y)=0\)</span>.</p>
<div id="thm-CS" class="theoreme theorem">
<p><span class="theorem-title"><strong>Theorem 3.1 (Inégalité de Cauchy-Schwarz) </strong></span>Si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont deux v.a. dans <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> alors la v.a. <span class="math inline">\(XY\)</span> est dans <span class="math inline">\(L^1(\Omega, \mathcal A, P)\)</span> et on a : <span class="math display">\[||XY||_{L^1}=\E[\ |XY|\ ]\leq ||X||_{L^2}||Y||_{L^2}.\]</span></p>
</div>
<p><br></p>
<div id="def-2O" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.10 </strong></span>Un processus <span class="math inline">\((X_t)_{t\in T}\)</span> est dit du <span style="color:blue;"><strong>second ordre</strong></span> si la v.a. <span class="math inline">\(X_t\)</span> est dans <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> pour tout <span class="math inline">\(t\)</span> dans <span class="math inline">\(T\)</span>.</p>
</div>
</section>
<section id="convergence-dans-l2" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="convergence-dans-l2"><span class="header-section-number">3.2.2</span> Convergence dans <span class="math inline">\(L^2\)</span></h3>
<div id="def-cvL2" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.11 </strong></span>Soient <span class="math inline">\((X_n)_{n\in \N}\)</span> une suite de v.a. dans <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> et <span class="math inline">\(X\)</span> une v.a. dans <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span>. On dit que <span class="math inline">\((X_n)_{n\in \N}\)</span> <span style="color:blue;"><strong>converge dans</strong> <span class="math inline">\(L^2\)</span></span> vers <span class="math inline">\(X\)</span> si l’on a : <span class="math display">\[
\lim_{n\to +\infty}||X_n-X||_{L^2}=0.
\]</span> Notation : <span class="math inline">\(X_n\underset{n\to +\infty}{\overset{L^2}{\longrightarrow}}X\)</span></p>
</div>
<p><br></p>
<p>La proposition suivante nous sera très utile dans la suite pour autoriser l’inversion entre le signe somme et l’espérance.</p>
<div id="prp-intsomme" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.1 </strong></span>Si <span class="math inline">\(\underset{i=0}{\stackrel{n}{\sum}}X_i\)</span> converge dans <span class="math inline">\(L^2\)</span> vers <span class="math inline">\(\underset{i=0}{\stackrel{+\infty}{\sum}}X_i\)</span> alors on a <span class="math display">\[
\E \left[ \underset{i=0}{\stackrel{+\infty}{\sum}}X_i \right]=\underset{i=0}{\stackrel{+\infty}{\sum}} \E[X_i].
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Notons <span class="math inline">\(U_n=\sum_{i=0}^nX_i\)</span> et <span class="math inline">\(U=\sum_{i=0}^{+\infty}X_i\)</span>. L’inégalité classique entre les normes <span class="math inline">\(L^1\)</span> et <span class="math inline">\(L^2\)</span> (obtenue par l’inégalité de Jensen par exemple) nous donne les inégalités : <span class="math display">\[
|\E [U_n]-\E[U]|\leq \E[ |U_n-U|]= || U_n-U ||_{L^1}\leq || U_n-U ||_{L^2}.
\]</span> L’hypothèse que <span class="math inline">\((U_n)\)</span> converge dans <span class="math inline">\(L^2\)</span> vers <span class="math inline">\(U\)</span> nous assure donc que <span class="math inline">\(\E[U_n]=\sum_{i=0}^n\E[X_i]\)</span> converge vers <span class="math inline">\(\E[U]=\E[\sum_{i=0}^{+\infty}X_i]\)</span>, dont découle l’égalité annoncée.</p>
</div>
</div>
</div>
<p>La <a href="#prp-intsomme">Proposition&nbsp;<span>3.1</span></a> reste valable pour une série indexée dans les deux directions :</p>
<p>si <span class="math inline">\(\underset{i=-m}{\stackrel{n}{\sum}}X_i\)</span> converge dans <span class="math inline">\(L^2\)</span> vers <span class="math inline">\(\underset{i=-\infty}{\stackrel{+\infty}{\sum}}X_i\)</span> quand <span class="math inline">\(n\)</span> et <span class="math inline">\(m\)</span> tendent vers <span class="math inline">\(+\infty\)</span>, on a <span class="math display">\[
\E \left[ \sum_{i=-\infty}^{+\infty}X_i \right]=\sum_{i=-\infty}^{+\infty} \E[X_i].
\]</span></p>
<div id="prp-cvprod" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.2 </strong></span>Si les séries <span class="math inline">\(\underset{i=0}{\stackrel{n}{\sum}}X_i\)</span> et <span class="math inline">\(\underset{j=0}{\stackrel{n}{\sum}}Y_j\)</span> convergent dans <span class="math inline">\(L^2\)</span> vers <span class="math inline">\(\underset{i=0}{\stackrel{+\infty}{\sum}}X_i\)</span> et <span class="math inline">\(\underset{j=0}{\stackrel{+\infty}{\sum}}Y_j\)</span> respectivement alors on a <span class="math display">\[
\E \left[ \sum_{i=0}^{+\infty}X_i \cdot \sum_{j=0}^{+\infty}Y_j  \right]=\sum_{i=0}^{+\infty}\sum_{j=0}^{+\infty} \E[X_iY_j].
\]</span></p>
</div>
<div id="cor-covserie" class="corollary theorem corollary">
<p><span class="theorem-title"><strong>Corollary 3.1 </strong></span>Si les séries <span class="math inline">\(\underset{i=0}{\stackrel{n}{\sum}}X_i\)</span> et <span class="math inline">\(\underset{j=0}{\stackrel{n}{\sum}}Y_j\)</span> convergent dans <span class="math inline">\(L^2\)</span> vers <span class="math inline">\(\underset{i=0}{\stackrel{+\infty}{\sum}}X_i\)</span> et <span class="math inline">\(\underset{j=0}{\stackrel{+\infty}{\sum}}Y_j\)</span> respectivement alors on a <span class="math display">\[
\C \left( \sum_{i=0}^{+\infty}X_i , \sum_{j=0}^{+\infty}Y_j  \right)=\sum_{i=0}^{+\infty}\sum_{j=0}^{+\infty} \C (X_i,Y_j).
\]</span></p>
</div>
</section>
<section id="projection-orthogonale" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="projection-orthogonale"><span class="header-section-number">3.2.3</span> Projection orthogonale</h3>
<p>Les projections dans l’espace <span class="math inline">\(L^2\)</span> s’appuient sur la propriété d’Hilbert de cet espace. Rappelons d’abord la définition d’un sous-espace vectoriel fermé d’un espace de Hilbert dans notre cadre.</p>
<div id="def-sevferme" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.12 </strong></span>Un <span style="color:blue;"><strong>sous-espace vectoriel</strong></span> <span class="math inline">\(\mathcal H\)</span> de l’espace <span class="math inline">\(L^2 (\Omega,\mathcal A,P)\)</span> est dit <span style="color:blue;"><strong>fermé</strong></span> s’il contient toutes ses limites <span class="math display">\[
\left(X_n\in \mathcal H, \forall n\in \N, \text{ et } X_n\underset{n\to +\infty}{\overset{L^2}{\to}}X \right)\implies X\in \mathcal H.
\]</span></p>
</div>
<p><br></p>
<div id="thm-proj" class="theoreme theorem">
<p><span class="theorem-title"><strong>Theorem 3.2 (Théorème de projection) </strong></span>Soit <span class="math inline">\(X\)</span> une v.a. dans <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span> et <span class="math inline">\(\mathcal H\)</span> un sous-espace vectoriel fermé de <span class="math inline">\(L^2(\Omega, \mathcal A, P)\)</span>. Il existe alors une unique v.a. <span class="math inline">\(\hat X\)</span> dans <span class="math inline">\(\mathcal H\)</span> telle que : <span class="math display">\[
||X-\hat X||_{L^2}=\min_{Y\in \mathcal H}||X-Y||_{L^2}.
\]</span></p>
<p>La v.a. <span class="math inline">\(\hat X\)</span> correspond à la <span style="color:blue;"><strong>projection orthogonale</strong></span> de <span class="math inline">\(X\)</span> sur l’espace <span class="math inline">\(\mathcal H\)</span> et est donc telle que : <span class="math display">\[
\hat X \in \mathcal H \text{ et }X-\hat X\perp \mathcal H.
\]</span></p>
</div>
</section>
</section>
<section id="processus-stationnaires" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="processus-stationnaires"><span class="header-section-number">3.3</span> Processus stationnaires</h2>
<p>On a vu dans le premier chapitre qu’une série temporelle peut souvent être décomposée sous la forme <span class="math display">\[
Y_t=m_t+s_t+X_t,
\]</span> où</p>
<ul>
<li><span class="math inline">\(m_t\)</span> est une fonction à variation lente appelée tendance</li>
<li><span class="math inline">\(s_t\)</span> une fonction périodique (de somme nulle) appelée saisonnalité.</li>
</ul>
<p>Le terme restant, le processus <span class="math inline">\(X_t\)</span>, est donc supposé être “plus stable” dans un sens que l’on va ici définir. C’est la notion de <strong>stationnarité</strong> que l’on va expliquer dans cette section.</p>
<div id="def-stationF" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.13 </strong></span>Un processus <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est dit <span style="color:blue;"><strong>stationnaire au sens fort</strong></span> si la loi de tout vecteur <span class="math inline">\((X_{t_1},\ldots,X_{t_n})\)</span> est invariante par translation temporelle : <span class="math display">\[
\mathcal L (X_{t_1},\ldots,X_{t_n})=\mathcal L (X_{t_1+h},\ldots,X_{t_n+h}),\ \forall (t_1,\ldots,t_n)\in \mathbb Z^n \textrm{ et } h\in \mathbb Z.
\]</span></p>
</div>
<p>Par conséquent, sous la stationnarité forte, toutes les v.a.r <span class="math inline">\(X_t\)</span> ont la même loi. On a immédiatement qu’un bruit blanc fort est stationnaire au sens fort.</p>
<p>Cette hypothèse de stationnarité forte est très contraignante et peu réaliste en pratique. Aussi on va lui préférer la notion de <strong>stationnarité faible</strong>. Pour introduire la notion de stationnarité faible pour les processus du second ordre, nous avons besoin de définir tout d’abord la <strong>fonction moyenne</strong> et la <strong>fonction covariance</strong> des processus du second ordre.</p>
<div id="def-moyCov" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.14 </strong></span>Soit <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> un processus du second ordre.</p>
<p>La <span style="color:blue;"><strong>fonction moyenne</strong></span> de <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est définie par <span class="math display">\[
t\in \Z \mapsto \mathbb E[X_t].
\]</span></p>
<p>La <span style="color:blue;"><strong>fonction covariance</strong></span> de <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est définie par : <span class="math display">\[\begin{eqnarray*}
(s,t)\in \mathbb Z^2 \mapsto \C(X_s,X_t)
&amp;=&amp;\mathbb E\left[(X_s-\E[X_s])(X_t-\E[X_t]) \right]\\
&amp;=&amp;\langle X_s-\E[X_s],X_t-\E[X_t]\rangle_{L^2}\\
&amp;=&amp;\mathbb E[X_sX_t]-\mathbb E[X_s]\mathbb E[X_t]
\end{eqnarray*}\]</span></p>
</div>
<p><br></p>
<div id="def-stationf" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.15 </strong></span>Un processus du second ordre <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est dit <span style="color:blue;"><strong>faiblement stationnaire</strong></span> si</p>
<ul>
<li>sa fonction moyenne est constante <span class="math inline">\(\E[X_t]=\mu_X,\ \forall t\in \mathbb Z\)</span>;</li>
<li>sa fonction covariance ne dépend que de la différence en temps <span class="math display">\[\begin{eqnarray*}
\C(X_s,X_t)
&amp;=&amp;\C(X_{s+u},X_{t+u}), \forall (s,t,u)\in \Z^3\\
&amp;=&amp;\C(X_0,X_{t-s})=f(t-s)
\end{eqnarray*}\]</span></li>
</ul>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remarques
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Un processus fortement stationnaire est stationnaire au sens faible. Mais la réciproque est fausse !</li>
<li>Si le processus est faiblement stationnaire alors <span class="math inline">\(\V (X_t)=\V (X_0),\ \forall t\in \mathbb Z.\)</span></li>
</ul>
</div>
</div>
<div id="exm-stationbb" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.1 (Bruit blanc fort / faible) </strong></span>Si le processus <span class="math inline">\((X_t)_{t\in \mathbb Z}\)</span> est un bruit blanc fort dans <span class="math inline">\(L^2\)</span> alors il est faiblement stationnaire puisque : <span class="math display">\[
\mu_X(t)=0,\ \forall t\in\mathbb Z
\textrm{  et }
\C(X_{t+h},X_t)=\sigma^2 \mathbb{1}_{h=0} = \left\{
\begin{array}{ccc}
\sigma^2&amp;\textrm{ si }&amp;h=0\\
0&amp;\textrm{ si }&amp;h\ne 0
\end{array}
\right.,\ \forall t\in\mathbb Z
\]</span></p>
<p>Un bruit blanc faible <span class="math inline">\(\text{WN}(0,\sigma^2)\)</span> est également faiblement stationnaire.</p>
</div>
<div id="exm-stationMarcheAlea" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.2 (Marche aléatoire non stationnaire) </strong></span>Soit <span class="math inline">\((S_t)_{t\in \mathbb N}\)</span> la marche aléatoire <span class="math inline">\(S_t = X_1+\ldots+X_t\)</span> avec <span class="math inline">\((X_t)_{t\in\mathbb Z}\sim \text{IID}(0,\sigma^2)\)</span> . On a <span class="math display">\[\begin{eqnarray*}
&amp; &amp;\mathbb E[S_t]=\mathbb E\left[ \sum_{k=1}^t X_k\right]=\sum_{k=1}^t\mathbb E[X_k]=0\\
&amp; &amp;\V(S_t)=\V\left(\sum_{k=1}^t X_k\right)=\sum_{k=1}^t \V(X_k)=t\sigma^2.
\end{eqnarray*}\]</span> <span class="math inline">\(\Longrightarrow\)</span> le processus <span class="math inline">\((S_t)_{t\in \mathbb N}\)</span> <strong>n’est pas stationnaire</strong> puisque sa variance n’est pas constante.</p>
<p>On peut le vérifier plus largement sur la fonction covariance : pour <span class="math inline">\(h\in\N\)</span>, <span class="math display">\[\begin{eqnarray*}
\C(S_{t+h},S_t)
&amp;=&amp;\C(S_t+X_{t+1}+\cdots +X_{t+h},S_t)\\
&amp;=&amp;\V(S_t)+\sum_{k=1}^h \C(X_{t+k},S_t)=\V(S_t)=t\sigma^2.
\end{eqnarray*}\]</span></p>
</div>
</section>
<section id="fonctions-dautocovariance-et-dautocorrélation" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="fonctions-dautocovariance-et-dautocorrélation"><span class="header-section-number">3.4</span> Fonctions d’autocovariance et d’autocorrélation</h2>
<section id="fonction-dautocovariance-acvf" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="fonction-dautocovariance-acvf"><span class="header-section-number">3.4.1</span> Fonction d’autocovariance (ACVF)</h3>
<div id="def-ACVF" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.16 </strong></span>Soit <span class="math inline">\((X_t)_{t\in\Z}\)</span> un processus faiblement stationnaire.</p>
<p>Sa <span style="color:blue;"><strong>fonction d’autocovariance</strong></span> <span class="math inline">\(\gamma_X(\cdot)\)</span> est la fonction définie par <span class="math display">\[\begin{eqnarray*}
\begin{array}{rcl}
\gamma_X:\mathbb Z&amp;\rightarrow &amp; \mathbb R\\
h&amp;\mapsto &amp; \gamma_X(h)=\C(X_h,X_0)=\C(X_{t+h},X_t),\ \forall t.
\end{array}
\end{eqnarray*}\]</span></p>
<p>Le tracé de la fonction <span class="math inline">\(h\in\mathbb N \mapsto \gamma_X(h)\)</span> est appelé <span style="color:blue;"><strong>autocovariogramme</strong></span>.</p>
</div>
<p><br></p>
<div id="prp-ACVF" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.3 </strong></span>La fonction d’autocovariance <span class="math inline">\(\gamma_X(.)\)</span> vérifie les propriétés suivantes :</p>
<ul>
<li><span class="math inline">\(\gamma_X(0)\geq 0\)</span></li>
<li><span class="math inline">\(|\gamma_X(h)|\leq \gamma_X (0)\)</span> pour tout <span class="math inline">\(h\)</span> donc l’ACVF est bornée</li>
<li><span class="math inline">\(\gamma_X(h)=\gamma_X(-h)\)</span> pour tout <span class="math inline">\(h\)</span> donc l’ACVF est une fonction paire</li>
</ul>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>On a <span class="math inline">\(\gamma_X(0)=\V(X_t)\geq 0\)</span>.</li>
<li>Comme une corrélation est toujours comprise dans l’intervalle <span class="math inline">\([-1,1]\)</span>, on a donc <span class="math inline">\(|\gamma_X(h)|\leq \gamma_X(0)\)</span>.</li>
<li>On peut écrire <span class="math inline">\(\gamma_X(h)=\C (X_{t+h}, X_t)=\C ( X_t,X_{t+h})=\gamma_X(-h)\)</span>.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="fonction-dautocorrélation-acf" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="fonction-dautocorrélation-acf"><span class="header-section-number">3.4.2</span> Fonction d’autocorrélation (ACF)</h3>
<div id="def-ACF" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.17 </strong></span>Soit <span class="math inline">\((X_t)_{t\in\Z}\)</span> un proecssus faiblement stationnaire.</p>
<p>Sa fonction <span style="color:blue;"><strong>d’autocorrélation</strong></span> <span class="math inline">\(\rho_X(\cdot)\)</span> est définie par <span class="math display">\[\begin{eqnarray*}
\begin{array}{rcl}
\rho_X:\mathbb Z&amp;\rightarrow &amp; [-1,1]\\
h&amp;\mapsto &amp; \rho_X(h)=\displaystyle \frac{\gamma_X(h)}{\gamma_X(0)}=\mbox{Corr}(X_{t+h},X_t)\\
&amp; &amp; \\
&amp; &amp; =\displaystyle\frac{\C(X_{t+h},X_t)}{\sqrt{\V(X_t) \V(X_{t+h})}},\ \forall t.
\end{array}
\end{eqnarray*}\]</span></p>
<p>Le tracé de la fonction <span class="math inline">\(h\in\mathbb N\mapsto \rho_X(h)\)</span> est appelé <span style="color:blue;"><strong>autocorrélogramme</strong></span>.</p>
</div>
<p><br></p>
<p>Ainsi les fonctions ACVF et ACF mesurent le degré de dépendance entre les valeurs d’une série temporelle à des instants différents. Ce sont des notions très importantes pour la suite du cours.</p>
</section>
<section id="exemples" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="exemples"><span class="header-section-number">3.4.3</span> Exemples</h3>
<div id="exm-ACVFbbG" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.3 (Bruit blanc gaussien) </strong></span><br> On considère la série <span class="math inline">\((\varepsilon_t)_{t\in T}\)</span> avec les <span class="math inline">\(\varepsilon_t\)</span> i.i.d <span class="math inline">\(\mathcal N(0,1)\)</span>. La trajectoire observée de cette série temporelle est représentée en <a href="#fig-exbbACF-1">Figure&nbsp;<span>3.5 (a)</span></a>. En traçant le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+1})\)</span> (voir <a href="#fig-exbbACF-2">Figure&nbsp;<span>3.5 (b)</span></a>), on constate qu’il n’y a pas de dépendance entre deux temps successifs. Sur l’autocorrélogramme empirique (<a href="#fig-exbbACF-3">Figure&nbsp;<span>3.5 (c)</span></a>), on a un pic à 1 pour <span class="math inline">\(h=0\)</span> et des valeurs proches de 0 pour <span class="math inline">\(h\geq 1\)</span>.</p>
<div id="fig-exbbACF" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exbbACF-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exbbACF-1.png" class="img-fluid figure-img" data-ref-parent="fig-exbbACF" width="672"></p>
<figcaption class="figure-caption">(a) Trajectoire de la série temporelle étudiée</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exbbACF-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exbbACF-2.png" class="img-fluid figure-img" data-ref-parent="fig-exbbACF" width="672"></p>
<figcaption class="figure-caption">(b) Nuage de points <span class="math inline">\((X_t, X_{t+1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-exbbACF-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-exbbACF-3.png" class="img-fluid figure-img" data-ref-parent="fig-exbbACF" width="672"></p>
<figcaption class="figure-caption">(c) Tracé de l’autocorrélogramme empirique</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.5: Exemple du bruit blanc gaussien</figcaption><p></p>
</figure>
</div>
</div>
<p><br></p>
<div id="exm-ACVFMA1" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.4 (Moyenne mobile d’ordre 1 MA(1)) </strong></span><br> Soit <span class="math inline">\((X_t)_{t\in \Z}\)</span> une série temporelle MA(1) définie par <span class="math display">\[
X_t = \varepsilon_t + \theta\ \varepsilon_{t-1}, \forall t\in\mathbb Z \textrm{ avec } (\varepsilon_t)_t\sim \text{WN}(0,\sigma^2).
\]</span></p>
<p>C’est un processus stationnaire au sens faible car</p>
<ul>
<li><span class="math inline">\(\E[X_t]=\E[\varepsilon_t] + \theta\ \E[\varepsilon_{t-1}]=0\)</span></li>
<li>La fonction d’autocovariance vaut</li>
</ul>
<span class="math display">\[\begin{eqnarray*}
\gamma_X(h)=\C(X_t,X_{t+h})
&amp;=&amp;\mathbb E\left[(\varepsilon_t+\theta \varepsilon_{t-1})(\varepsilon_{t+h}+\theta \varepsilon_{t+h-1})\right]\\
&amp;=&amp; \E[\varepsilon_t\ \varepsilon_{t+h}] +
\E[\varepsilon_t\ \theta \varepsilon_{t+h-1}]\\
&amp; &amp; +
\E[\theta \varepsilon_{t-1} \varepsilon_{t+h}]+
\E[\theta \varepsilon_{t-1}\ \theta \varepsilon_{t+h-1}]\\
&amp;=&amp; \sigma^2 (\mathbb{1}_{h=0} + \theta \mathbb{1}_{h=1} + \theta\mathbb{1}_{h=-1} + \theta^2\mathbb{1}_{h=0})\\
&amp;=&amp;\left\{
\begin{array}{lcc}
\sigma^2(1+\theta^2)&amp; \textrm{ si } &amp;h=0\\
\theta \sigma^2 &amp; \textrm{ si } &amp; |h|=1\\
0 &amp; \textrm{ si } &amp;|h|\geq 2
\end{array}
\right.
\end{eqnarray*}\]</span>
<p>On en déduit l’expression de la fonction d’autocorrélation :</p>
<p><span class="math display">\[
\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)}
=\left\{
\begin{array}{lcc}
1&amp; \textrm{ si } &amp;h=0\\
\frac{\theta}{1+ \theta^2} &amp; \textrm{ si } &amp; |h|=1\\
0 &amp; \textrm{ si } &amp;|h|\geq 2
\end{array}
\right.
\]</span></p>
<p>Pour illustrer, on observe la trajectoire d’une série temporelle issue du modèle suivant <span class="math display">\[
X_t = \varepsilon_t -0.7 \varepsilon_{t-1}, \forall t\in\mathbb Z \textrm{ avec } (\varepsilon_t)_t\sim \text{WN}(0,0.5^2)
\]</span></p>
<p>La trajectoire observée de cette série temporelle est représentée en <a href="#fig-ex1MA-1">Figure&nbsp;<span>3.6 (a)</span></a>. On constate une dépendance linéaire quand on trace le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+1})\)</span> (voir <a href="#fig-ex1MA-2">Figure&nbsp;<span>3.6 (b)</span></a>) et aucune pour le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+2})\)</span> (voir <a href="#fig-ex1MA-3">Figure&nbsp;<span>3.6 (c)</span></a>). Sur l’autocorrélogramme empirique (<a href="#fig-ex1MA-4">Figure&nbsp;<span>3.6 (d)</span></a>), on a un pic à 1 pour <span class="math inline">\(h=0\)</span>, un pic proche de <span class="math inline">\(\frac{-0.7}{1 + (-0.7)^2}\approx -0.47\)</span> pour <span class="math inline">\(h=1\)</span>, et des valeurs proches de 0 pour <span class="math inline">\(h\geq 2\)</span>.</p>
<div id="fig-ex1MA" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1MA-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1MA-1.png" class="img-fluid figure-img" data-ref-parent="fig-ex1MA" width="672"></p>
<figcaption class="figure-caption">(a) Trajectoire de la série temporelle étudiée</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1MA-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1MA-2.png" class="img-fluid figure-img" data-ref-parent="fig-ex1MA" width="672"></p>
<figcaption class="figure-caption">(b) Nuage de points <span class="math inline">\((X_t, X_{t+1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1MA-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1MA-3.png" class="img-fluid figure-img" data-ref-parent="fig-ex1MA" width="672"></p>
<figcaption class="figure-caption">(c) Nuage de points <span class="math inline">\((X_t, X_{t+2})\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1MA-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1MA-4.png" class="img-fluid figure-img" data-ref-parent="fig-ex1MA" width="672"></p>
<figcaption class="figure-caption">(d) Tracé de l’autocorrélogramme empirique</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.6: Résultats pour la série MA(1) <span class="math inline">\(X_t = \varepsilon_t -0.7 \varepsilon_{t-1}\)</span></figcaption><p></p>
</figure>
</div>
<p>Comme second exemple, on observe la trajectoire d’une série temporelle issue du modèle suivant <span class="math display">\[
X_t = \varepsilon_t +\varepsilon_{t-1}, \forall t\in\mathbb Z \textrm{ avec } (\varepsilon_t)_t\sim \text{WN}(0,0.5^2)
\]</span> La trajectoire observée de cette série temporelle est représentée en <a href="#fig-ex2MA-1">Figure&nbsp;<span>3.7 (a)</span></a>. On constate une dépendance linéaire avec pente positive quand on trace le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+1})\)</span> (voir <a href="#fig-ex2MA-2">Figure&nbsp;<span>3.7 (b)</span></a>) et aucune pour le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+2})\)</span> (voir <a href="#fig-ex2MA-3">Figure&nbsp;<span>3.7 (c)</span></a>). Sur l’autocorrélogramme empirique (<a href="#fig-ex2MA-4">Figure&nbsp;<span>3.7 (d)</span></a>), on a un pic à 1 pour <span class="math inline">\(h=0\)</span>, un pic proche de <span class="math inline">\(\frac{1}{1 + (1)^2}=\frac 1 2\)</span> pour <span class="math inline">\(h=1\)</span>, et des valeurs proches de 0 pour <span class="math inline">\(h\geq 2\)</span>.</p>
<div id="fig-ex2MA" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2MA-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2MA-1.png" class="img-fluid figure-img" data-ref-parent="fig-ex2MA" width="672"></p>
<figcaption class="figure-caption">(a) Trajectoire de la série temporelle étudiée</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2MA-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2MA-2.png" class="img-fluid figure-img" data-ref-parent="fig-ex2MA" width="672"></p>
<figcaption class="figure-caption">(b) Nuage de points <span class="math inline">\((X_t, X_{t+1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2MA-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2MA-3.png" class="img-fluid figure-img" data-ref-parent="fig-ex2MA" width="672"></p>
<figcaption class="figure-caption">(c) Nuage de points <span class="math inline">\((X_t, X_{t+2})\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2MA-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2MA-4.png" class="img-fluid figure-img" data-ref-parent="fig-ex2MA" width="672"></p>
<figcaption class="figure-caption">(d) Tracé de l’autocorrélogramme empirique</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.7: Résultats pour la série MA(1) <span class="math inline">\(X_t = \varepsilon_t + \varepsilon_{t-1}\)</span></figcaption><p></p>
</figure>
</div>
</div>
<p><br></p>
<div id="exm-ACVFAR" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.5 (Processus autorégressif d’ordre 1 AR(1)) </strong></span><br></p>
<p>Soit <span class="math inline">\((X_t)_{t\in\mathbb Z}\)</span> le processus stationnaire défini par <span class="math display">\[
X_t=\phi X_{t-1}+\varepsilon_t,\ \forall t\in \mathbb Z
    \textrm{ avec }(\varepsilon_t)\sim \text{WN}(0,\sigma^2) \textrm{ et } 0&lt;|\phi|&lt;1
\]</span></p>
<p>On suppose que le processus <span class="math inline">\((\varepsilon_t)_{t\in\mathbb Z}\)</span> est tel que, pour tout <span class="math inline">\(t\)</span>, <span class="math display">\[\begin{eqnarray*}
\C(\varepsilon_t,X_s)=0, \ \forall s&lt;t
&amp;\iff&amp; \langle \varepsilon_t,X_s\rangle_{L^2}=0, \ \forall s&lt;t\\
&amp;\iff&amp; \varepsilon_t \bot \mathcal{H}_{t-1}:=sp\{X_{t-1},X_{t-2},\ldots\}.
\end{eqnarray*}\]</span></p>
<p>Le processus <span class="math inline">\(X_t\)</span> est centré car : <span class="math inline">\(\E[X_t] = \phi \E[X_{t-1}] + \E[\varepsilon_t] = \phi \mathbb E [X_{t-1}] + 0\)</span>. Or le processus <span class="math inline">\((X_t)_{t\in\Z}\)</span> est stationnaire donc <span class="math inline">\(\E[X_t]=\E[X_{t-1}]\)</span>. On obtient donc que <span class="math inline">\(\E[X_t] = \phi \mathbb E [X_{t}]\)</span> d’où <span class="math inline">\(\mathbb E[X_t] =0\)</span> car <span class="math inline">\(\phi\neq 0\)</span>.</p>
<p>Déterminons maintenant la fonction d’autocovariance / autocorrélation : soit <span class="math inline">\(h\in\mathbb N\)</span>, <span class="math display">\[\begin{eqnarray*}
\gamma_X(h)=\C(X_t,X_{t+h})
&amp;=&amp;\mathbb E[X_tX_{t+h}]\\
&amp;=&amp;\mathbb E[\left(\phi X_{t+h-1}+\varepsilon_{t+h}\right)X_t]\\
&amp;=&amp;\phi \C(X_{t+h-1},X_t)+ \C(\varepsilon_{t+h},X_t).
\end{eqnarray*}\]</span></p>
<p>Or par hypothèse, <span class="math inline">\(\varepsilon_t \bot \mathcal{H}_{t-1}\)</span> donc <span class="math display">\[
\gamma_X(h)=\phi\gamma_X(h-1)=\cdots=\phi^h\gamma_X(0).
\]</span></p>
<p>D’où <span class="math inline">\(\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)}=\phi^h,\ \forall h&gt;0\)</span>. Finalement, comme <span class="math inline">\(\gamma_X(h)= \gamma_X(-h)\)</span>, <span class="math inline">\(\rho_X(h)= \phi^{|h|},\ \forall h\in \mathbb Z.\)</span></p>
<p>Pour illustrer ce résultat, on observe une série temporelle simulée selon <span class="math display">\[
X_t = 0.8 X_{t-1} +\varepsilon_{t}, \forall t\in\mathbb Z \textrm{ avec } (\varepsilon_t)_t\sim \text{WN}(0,0.5^2)
\]</span></p>
<p>La trajectoire observée de cette série temporelle est représentée en <a href="#fig-ex1AR-1">Figure&nbsp;<span>3.8 (a)</span></a>. On constate des dépendances linéaires quand on trace le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+1})\)</span> (voir <a href="#fig-ex1AR-2">Figure&nbsp;<span>3.8 (b)</span></a>) et le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+2})\)</span> (voir <a href="#fig-ex1AR-3">Figure&nbsp;<span>3.8 (c)</span></a>). Sur l’autocorrélogramme empirique (<a href="#fig-ex1AR-4">Figure&nbsp;<span>3.8 (d)</span></a>), on constate la décroissance exponentielle vers 0 (<span class="math inline">\(\rho_X(h) = e^{|h| \ln(0.8)}\approx e^{-0.22\ |h|}\)</span>).</p>
<div id="fig-ex1AR" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1AR-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1AR-1.png" class="img-fluid figure-img" data-ref-parent="fig-ex1AR" width="672"></p>
<figcaption class="figure-caption">(a) Trajectoire de la série temporelle étudiée</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1AR-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1AR-2.png" class="img-fluid figure-img" data-ref-parent="fig-ex1AR" width="672"></p>
<figcaption class="figure-caption">(b) Nuage de points <span class="math inline">\((X_t, X_{t+1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1AR-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1AR-3.png" class="img-fluid figure-img" data-ref-parent="fig-ex1AR" width="672"></p>
<figcaption class="figure-caption">(c) Nuage de points <span class="math inline">\((X_t, X_{t+2})\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex1AR-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex1AR-4.png" class="img-fluid figure-img" data-ref-parent="fig-ex1AR" width="672"></p>
<figcaption class="figure-caption">(d) Tracé de l’autocorrélogramme empirique</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.8: Résultats pour la série AR(1) <span class="math inline">\(X_t = 0.8 X_{t-1} +\varepsilon_{t}\)</span></figcaption><p></p>
</figure>
</div>
<p>Pour la seconde illustration, on considère la série temporelle <span class="math display">\[
X_t = -0.8 X_{t-1} +\varepsilon_{t}, \forall t\in\mathbb Z \textrm{ avec } (\varepsilon_t)_t\sim \text{WN}(0,0.5^2)
\]</span> La trajectoire observée de cette série temporelle est représentée en <a href="#fig-ex2AR-1">Figure&nbsp;<span>3.9 (a)</span></a>. On constate des dépendances linéaires quand on trace le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+1})\)</span> (voir <a href="#fig-ex2AR-2">Figure&nbsp;<span>3.9 (b)</span></a>) et le nuage de points de coordonnées <span class="math inline">\((X_t,X_{t+2})\)</span> (voir <a href="#fig-ex2AR-3">Figure&nbsp;<span>3.9 (c)</span></a>), avec des pentes qui changent de signe car <span class="math inline">\(\phi&lt;0\)</span>. Sur l’autocorrélogramme empirique (<a href="#fig-ex2AR-4">Figure&nbsp;<span>3.9 (d)</span></a>), on constate la décroissance vers 0 avec alternance du signe (<span class="math inline">\(\rho_X(h) = (-1)^{|h|} e^{|h| \ln(0.8)}\approx (-1)^{|h|} e^{-0.22\ |h|}\)</span>).</p>
<div id="fig-ex2AR" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2AR-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2AR-1.png" class="img-fluid figure-img" data-ref-parent="fig-ex2AR" width="672"></p>
<figcaption class="figure-caption">(a) Trajectoire de la série temporelle étudiée</figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2AR-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2AR-2.png" class="img-fluid figure-img" data-ref-parent="fig-ex2AR" width="672"></p>
<figcaption class="figure-caption">(b) Nuage de points <span class="math inline">\((X_t, X_{t+1})\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2AR-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2AR-3.png" class="img-fluid figure-img" data-ref-parent="fig-ex2AR" width="672"></p>
<figcaption class="figure-caption">(c) Nuage de points <span class="math inline">\((X_t, X_{t+2})\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-ex2AR-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="chap2_files/figure-html/fig-ex2AR-4.png" class="img-fluid figure-img" data-ref-parent="fig-ex2AR" width="672"></p>
<figcaption class="figure-caption">(d) Tracé de l’autocorrélogramme empirique</figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.9: Résultats pour la série AR(1) <span class="math inline">\(X_t = -0.8 X_{t-1} +\varepsilon_{t}\)</span></figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="cns-pour-une-fonction-dautocovariance" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="cns-pour-une-fonction-dautocovariance"><span class="header-section-number">3.4.4</span> CNS pour une fonction d’autocovariance</h3>
<div id="def-semidef" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.18 </strong></span>Une fonction <span class="math inline">\(K: \mathbb Z \rightarrow \mathbb R\)</span> est dite <span style="color:blue;"><strong>semi-définie positive</strong></span> si l’on a <span class="math display">\[
\sum_{i,j=1}^na_ia_jK(i-j)\geq 0,
\]</span> pour tout <span class="math inline">\(n\)</span> et tout vecteur <span class="math inline">\((a_1,\ldots,a_n)\in\R^n\)</span>.</p>
</div>
<p><br></p>
<div id="thm-CNSACF" class="theoreme theorem">
<p><span class="theorem-title"><strong>Theorem 3.3 </strong></span>Une fonction réelle définie sur <span class="math inline">\(\Z\)</span> est une fonction d’autocovariance d’une série temporelle <strong>si et seulement si</strong> elle est paire et semi-définie positive.</p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math inline">\(\Rightarrow\)</span>) : Soit <span class="math inline">\(\gamma_X(.)\)</span> la fonction d’autocovariance de <span class="math inline">\((X_t)_{t\in\Z}\)</span>. On a déjà montré précédemment qu’elle est paire. Montrons qu’elle est semi-définie positive: soit <span class="math inline">\((a_1,\ldots,a_n)\in\R^n\)</span>,</p>
<span class="math display">\[\begin{eqnarray*}
\underset{i=1}{\stackrel{n}{\sum}}\underset{j=1}{\stackrel{n}{\sum}} a_i a_j \gamma_X(i-j) &amp;=&amp; \underset{i=1}{\stackrel{n}{\sum}}\underset{j=1}{\stackrel{n}{\sum}} a_i a_j \C(X_{t-i},X_{t-j})\\
&amp;= &amp; \C\left(\underset{i=1}{\stackrel{n}{\sum}} a_i X_{t-i}, \underset{j=1}{\stackrel{n}{\sum}}a_j X_{t-j}\right)\\
&amp;=&amp; \V\left(\underset{i=1}{\stackrel{n}{\sum}} a_i X_{t-i}\right) \geq 0.
\end{eqnarray*}\]</span>
<p><br> <span class="math inline">\(\Leftarrow\)</span>) Soit <span class="math inline">\(K:\Z\rightarrow\R\)</span> paire et demi-définie positive. On veut montrer qu’il existe un processus stationnaire tel que <span class="math inline">\(\gamma_X(.)=K(.)\)</span>. <br></p>
<p><span class="math inline">\(\forall n\in\N^\star,\ \forall \mathbf{t}=(t_1,\ldots,t_n)\in\Z^n\)</span>. Soit <span class="math inline">\(F_{\mathbf{t}}\)</span> la loi sur <span class="math inline">\(\R^n\)</span> de fonction caractéristique <span class="math display">\[
\Phi_{\mathbf{t}}(\mathbf{u}) = \exp\left[-\frac 1 2 \mathbf{u}' \mathbb K \mathbf{u}\right]
\]</span> où <span class="math inline">\(\mathbf{u}=(u_1,\ldots,u_n)'\in\R^n\)</span> et la matrice <span class="math inline">\(\mathbb{K}=(K(t_i - t_j))_{i,j=1,\ldots,n}\)</span>. <br> Comme <span class="math inline">\(K\)</span> est semi-définie positive, <span class="math inline">\(\mathbb{K}\)</span> est une matrice semi-définie positive et donc <span class="math inline">\(\Phi_{\mathbf{t}}(.)\)</span> est la fonction caractéristique d’un vecteur gaussien <span class="math inline">\(\mathcal{N}(0,\mathbb K)\)</span>.</p>
<p>On peut alors vérifier que <span class="math display">\[
\underset{u_i\rightarrow 0}{\lim} \Phi_{\mathbf t}(\mathbf u) = \Phi_{\mathbf{t}_{-i}}(\mathbf{u}_{-i}) = \exp\left[-\frac 1 2 \mathbf{u}_{-i}' \mathbb{K}_{\mathbf{t}_{-i}} \mathbf{u}_{-i}\right]
\]</span> où <span class="math inline">\(\mathbf{t}_{-i} = (t_1,\ldots,t_{i-1},t_{i+1},\ldots,t_n)'\)</span> et <span class="math inline">\(\mathbf{u}_{-i} = (u_1,\ldots, u_{i-1}, u_{i+1},\ldots,u_n)'\)</span>. On conclut la preuve en utilisant le théorème d’existence de Kolmogorov : <br> <span class="math inline">\(\{F_{\mathbf{t}}(.),\ \mathbf{t}\in \mathcal{T}\}\)</span> sont les fonctions de distribution d’un processus stochastique si et seulement si pour tout <span class="math inline">\(n\)</span>, <span class="math inline">\(\mathbf{t}=(t_1,\ldots,t_n)\in\mathcal{T}\)</span>, <span class="math inline">\(\mathbf{x}\in\R^n\)</span> et <span class="math inline">\(1\leq k \leq n\)</span>, <span class="math display">\[
\underset{x_k\rightarrow \infty}{\lim}
F_{\mathbf{t}}(\mathbf{x}) = F_{\mathbf{t}_{-k}}(\mathbf{x}_{-k})
\]</span> où <span class="math inline">\(\mathbf{t}_{-k} = (t_1,\ldots,t_{k-1},t_{k+1},\ldots,t_n)'\)</span> et <span class="math inline">\(\mathbf{x}_{-k} = (x_1,\ldots, x_{k-1}, x_{k+1},\ldots,x_n)'\)</span>.</p>
</div>
</div>
</div>
<p><br></p>
<p>Remarque : Pour la fonction d’autocorrélation, on a les mêmes propriétés + <span class="math inline">\(\rho_X(0)=1\)</span>.</p>
</section>
<section id="matrice-dautocorrélation" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="matrice-dautocorrélation"><span class="header-section-number">3.4.5</span> Matrice d’autocorrélation</h3>
<div id="def-matriceACF" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.19 </strong></span>Soit <span class="math inline">\((X_t)_{t\in \Z}\)</span> est un processus stationnaire du second ordre. On appelle <span style="color:blue;"><strong>matrice d’autocorrélation</strong></span> de <span class="math inline">\((X_t,\ldots,X_{t+h-1})\)</span> pour <span class="math inline">\(h\in\N^*\)</span> <span class="math display">\[
R_{X,h}=\left(
\begin{array}{cccc}
1 &amp; \rho_X(1)  &amp; \cdots &amp; \rho_X(h-1)  \\
\rho_X(1)  &amp;1   &amp; \ddots &amp;\rho_X(h-2)  \\
\vdots  &amp;  \ddots &amp;   \ddots &amp;\vdots\\
\rho_X(h-1) &amp;\cdots&amp;\rho_X(1)&amp; 1
\end{array}
\right).
\]</span></p>
</div>
<p><br></p>
<p>Cette matrice d’autocorrélation est une <strong>matrice de Toeplitz</strong> (matrice à diagonales constantes) et</p>
<p><span class="math display">\[
R_{X,h}=\left(
\begin{array}{ccc|c}
  &amp; &amp;  &amp; \rho_X(h-1)  \\
&amp;R_{X,h-1}  &amp;  &amp;\rho_X(h-2)  \\
  &amp;   &amp;    &amp;\vdots\\
    &amp;   &amp;    &amp;\rho_X(1)\\
  \hline
\rho_X(h-1) &amp;\cdots&amp;\rho_X(1)&amp; 1
\end{array}
\right)
\]</span></p>
<p>La fonction d’autocorrélation vérifie la même propriété de semi-définie positivité que la fonction d’autocovariance. La proposition suivante donne en outre une condition équivalente en terme du déterminant des matrices <span class="math inline">\(R_{X,h}\)</span>.</p>
<div id="prp-Sylvester" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.4 </strong></span>La fonction d’autocorrélation est également une fonction semi-définie positive. D’après le critère de Sylvester, cette propriété est équivalente à la positivité de tous les déterminants des mineurs principaux <span class="math display">\[
\mbox{det}(R_{X,h})\geq 0,\ \textrm{ pour tout } h
\]</span></p>
</div>
<p>Cette propriété fixe une infinité de contraintes sur les corrélations</p>
<ul>
<li><span class="math inline">\(\mbox{det}(R_{X,2})\geq 0\)</span> donne <span class="math inline">\(\rho_X^2(1)\leq 1\)</span></li>
<li><span class="math inline">\(\mbox{det}(R_{X,3})\geq 0\)</span> donne <span class="math inline">\((1-\rho_X(2))(1+\rho_X(2)-2\rho_X^2(1))\geq 0\)</span>, et donc <span class="math inline">\(1+\rho_X(2)-2\rho_X^2(1)\geq 0\)</span>,</li>
<li>et ainsi de suite…</li>
</ul>
</section>
<section id="premiers-pas-vers-les-processus-arma" class="level3" data-number="3.4.6">
<h3 data-number="3.4.6" class="anchored" data-anchor-id="premiers-pas-vers-les-processus-arma"><span class="header-section-number">3.4.6</span> Premiers pas vers les processus ARMA</h3>
<p>Les processus ARMA seront au coeur du <a href="chap4.html"><span>Chapter&nbsp;5</span></a>. Nous les abordons ici très rapidement pour parler de <strong>filtrage linéaire</strong>.</p>
<p>Dans la modélisation ARMA, on utilise un opérateur de série en <span class="math inline">\(B\)</span> de coefficients <span class="math inline">\((\psi_j)_{j\in \Z}\)</span> <span class="math display">\[
\psi(B)=\sum_{j\in \Z}\psi_j B^j
\]</span></p>
<p>que l’on applique sur un processus stationnaire. On parle alors de <span style="color:blue;"><strong>filtrage linéaire</strong></span>. Si <span class="math inline">\((X_t)_{t\in \Z}\)</span> est une série temporelle stationnaire alors <span class="math display">\[
Y_t=\psi(B) X_t = \sum_{j\in\mathbb Z}\psi_j X_{t-j}
\]</span></p>
<p>On reviendra dans le <a href="chap4.html"><span>Chapter&nbsp;5</span></a> sur cette notion de série en <span class="math inline">\(B\)</span> pour mieux la définir et établir des résultats. Nous allons ici nous intéresser à la propriété de maintien de la propriété de stationnairité par le filtrage linéaire sous une condition de sommabilité de ses coefficients.</p>
<div id="prp-filtragelin" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.5 (Filtrage linéaire) </strong></span>Soit <span class="math inline">\((X_t)_{t\in \Z}\)</span> une série temporelle <strong>stationnaire</strong> de fonction moyenne <span class="math inline">\(\mu_X\)</span> et de fonction d’autocovariance <span class="math inline">\(\gamma_X(\cdot)\)</span>.</p>
<p>Si la suite de réels <span class="math inline">\((\psi_j)_{j\in \Z}\)</span> est sommable (<span style="color:red;"><span class="math inline">\(\sum_{j=-\infty}^{+\infty}|\psi_j|&lt;+\infty\)</span></span>) alors la série <span class="math inline">\((Y_t)_{t\in \Z}\)</span> obtenue par filtrage linéaire de <span class="math inline">\((X_t)_{t\in \Z}\)</span>, <span class="math display">\[
Y_t=\psi(B)X_t=\sum_{j=-\infty}^{+\infty}\psi_j X_{t-j},
\]</span> existe et est également <strong>stationnaire</strong>.</p>
<p>La moyenne est donnée par la relation <span class="math display">\[
\mu_Y = \mu_X\sum_{j=-\infty}^{+\infty}\psi_j
\]</span></p>
<p>et la fonction d’autocovariance vaut <span class="math display">\[
\gamma_Y(h) =\sum_{i=-\infty}^{+\infty}\sum_{j=-\infty}^{+\infty}\psi_i\psi_j\gamma_X(h+i-j),\ \forall h\in\Z
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Existence de la série <span class="math inline">\((Y_t)_{t\in\Z}\)</span> :</li>
</ul>
<p>On a <span class="math inline">\(\underset{j\in \Z}{\sum} \|\psi_j X_{t-j}\|_{L^2} = \underset{j\in \Z}{\sum} |\psi_j| \|X_{t-j}\|_{L^2}\)</span>. Or <span class="math inline">\(\|X_{t-j}\|_{L^2}^2=\E[X_{t-j}^2]= \V(X_{t-j}) + \E[X_{t-j}]^2 = \gamma_X(0)+\mu_X^2.\)</span> Ainsi <span class="math inline">\(\underset{j\in \Z}{\sum} \|\psi_j X_{t-j}\|_{L^2} = \sqrt{\gamma_X(0)+\mu_X^2}\underset{j\in \Z}{\sum} |\psi_j| &lt;+\infty\)</span>. Donc la série <span class="math inline">\((Y_t)_{t\in\Z}\)</span> est bien définie.</p>
<ul>
<li>Série du second ordre :</li>
</ul>
<p><span class="math inline">\(\|Y_t\|_{L^2} = \|\underset{j\in\Z}{\sum} \psi_j X_{t-j}\|_{L^2} \leq \underset{j\in\Z}{\sum} \|\psi_j X_{t-j}\|_{L^2} &lt; +\infty\)</span></p>
<ul>
<li><p>La fonction moyenne de <span class="math inline">\((Y_t)_{t\in\Z}\)</span> : <span class="math inline">\(\E[Y_t] = \E\left[ \underset{j\in\Z}{\sum} \psi_j X_{t-j} \right] = \underset{j\in\Z}{\sum} \psi_j \E\left[X_{t-j} \right] = \mu_X \left(\underset{j\in\Z}{\sum} \psi_j \right)\)</span> car <span class="math inline">\(\underset{j\in\Z}{\sum}|\psi_j|&lt;+\infty\)</span>. Donc la fonction moyenne est constante.</p></li>
<li><p>La fonction d’autocovariance de <span class="math inline">\((Y_t)_{t\in\Z}\)</span> : <span class="math display">\[\begin{eqnarray*}
\C(Y_t,Y_{t+h})
&amp;=&amp; \C\left(\underset{i\in\Z}{\sum} \psi_j X_{t-i}, \underset{j\in\Z}{\sum} \psi_i X_{t+h-j} \right)\\
&amp;=&amp; \underset{j\in\Z}{\sum} \underset{i\in\Z}{\sum} \psi_i\psi_j \C\left(X_{t-i},X_{t+h-j}\right)\\
&amp;=&amp;\underset{j\in\Z}{\sum} \underset{i\in\Z}{\sum} \psi_i\psi_j \gamma_X(h+i-j)\\
&amp;=&amp; f(h)
\end{eqnarray*}\]</span> car <span class="math inline">\(\underset{j\in\Z}{\sum}|\psi_j|&lt;+\infty\)</span> (échange <span class="math inline">\(\C(.,.)\)</span> et <span class="math inline">\(\sum\)</span>, voir <a href="#cor-covserie">Corollary&nbsp;<span>3.1</span></a>).</p></li>
</ul>
<p>Ainsi <span class="math inline">\((Y_t)_{t\in\Z}\)</span> est un processus faiblement stationnaire.</p>
</div>
</div>
</div>
<div id="exm-FLbb" class="exemple theorem example">
<p><span class="theorem-title"><strong>Example 3.6 (Filtrage linéaire d’un bruit blanc) </strong></span><br> Dans cet exemple, on considère que le processus initial est un bruit blanc <span class="math display">\[
(\varepsilon_t)_{t\in\mathbb Z}\sim \text{WN}(0,\sigma^2)
\]</span> qui est donc stationnaire.</p>
<p>Le processus <span class="math inline">\((Y_t)_{t\in \Z}\)</span> défini par <span class="math display">\[
Y_t=\sum_{j\in \Z}\psi_j\ \varepsilon_{t-j}
\]</span> avec <span class="math inline">\(\sum_{j\in \Z}|\psi_j | &lt;+\infty\)</span> est bien défini et stationnaire. La fonction moyenne de <span class="math inline">\((Y_t)_{t\in\Z}\)</span> est <span class="math display">\[
\mu_Y=\mu_\varepsilon \sum_{j\in \Z}\psi_j =0
\]</span> et de fonction d’autocovariance <span class="math display">\[\begin{eqnarray*}
\gamma_Y(h)&amp;=&amp;\sum_{i\in \Z} \sum_{j\in \Z} \psi_i \psi_j \gamma_\varepsilon(h+i-j)\\
&amp;=&amp; \sigma^2 \sum_{i\in \Z} \sum_{j\in \Z} \psi_i \psi_j \mathbb{1}_{h+i-j=0}\\
&amp;=&amp;\sigma^2\ \sum_{i\in \Z} \psi_i \psi_{h+i}
\end{eqnarray*}\]</span> car <span class="math inline">\(\gamma_\varepsilon(u)= \sigma^2\ \mathbb{1}_{u = 0}\)</span>.</p>
<p>Et pour une somme finie ?</p>
<p>Soit <span class="math inline">\((\varepsilon_t)_{t\in \Z}\sim\text{WN}(0,\sigma^2)\)</span> et le processus <span class="math inline">\((Y_t)_{t\in \Z}\)</span> défini par <span class="math display">\[
Y_t=\sum_{i=0}^t\varepsilon_{t-i}
\]</span></p>
<p>Le processus <span class="math inline">\((Y_t)_{t\in \Z}\)</span> existe et il est du second ordre.</p>
<p>Le processus reste centré <span class="math inline">\(\E[Y_t]=\underset{i=0}{\stackrel{t}{\sum}}\E[\varepsilon_{t-i}]=0.\)</span></p>
<p>Fonction de covariance : soit <span class="math inline">\(h\in\mathbb N\)</span>, <span class="math display">\[\begin{eqnarray*}
\C(Y_t,Y_{t+h})
&amp;=&amp;\E\left[\sum_{i=0}^t\varepsilon_{t-i}\times \sum_{j=0}^{t+h}\varepsilon_{t+h-j}\right]\\
&amp;=&amp;\sum_{i=0}^{t} \E[\varepsilon_i^2]=\sigma^2\ (1+t).
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(\Longrightarrow\)</span> <strong>Le processus n’est donc pas stationnaire!</strong> Ainsi, de manière paradoxale, les sommes finies peuvent poser plus de “problèmes” que les sommes infinies !</p>
</div>
</section>
</section>
<section id="densité-spectrale" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="densité-spectrale"><span class="header-section-number">3.5</span> Densité spectrale</h2>
<p>Jusqu’ici, on a abordé les processus stationnaires du second ordre via leur représentation temporelle. On peut également s’intéresser à leur représentation dans le domaine des fréquences. On aborde alors la notion de <strong>densité spectrale</strong> qui est une fonction contenant la même information que la fonction d’autocovariance.</p>
<div id="def-denspect" class="definition theorem definition">
<p><span class="theorem-title"><strong>Definition 3.20 </strong></span>Soit <span class="math inline">\((X_t)_{t\in \Z}\)</span> un processus stationnaire de fonction d’autocovariance <span class="math inline">\(\gamma_X(\cdot)\)</span>. On appelle <span style="color:blue;"><strong>densité spectrale</strong></span>, quand elle existe, la fonction <span class="math inline">\(f_X(\cdot)\)</span> définie sur <span class="math inline">\(\R\)</span> par <span class="math display">\[
f_X(\omega)=\frac{1}{2\pi}\sum_{h\in \Z}\gamma_X(h)e^{-i\omega h}.
\]</span></p>
</div>
<p>On peut reconnaitre que cette densité spectrale revient à la transformée de Fourier discrète de la fonction <span class="math inline">\(\gamma_X(\cdot)\)</span> définie sur <span class="math inline">\(\Z\)</span>.</p>
<p>La proposition suivante donne une propriété d’existence de la densité spectrale.</p>
<div id="prp-existdenspect" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.6 (Existence de la densité spectrale) </strong></span><br> La densité spectrale d’un processus stationnaire <span class="math inline">\((X_t)_{t\in \Z}\)</span> de fonction d’autocovariance <span class="math inline">\(\gamma_X(\cdot)\)</span> existe dès que l’on a : <span class="math display">\[
\sum_{h\in \Z}|\gamma_X(h)|&lt;+\infty.
\]</span></p>
</div>
<div id="prp-propdenspect" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.7 </strong></span>La densité spectrale d’un processus stationnaire <span class="math inline">\((X_t)_{t\in \Z}\)</span> est une fonction réelle, continue, positive, paire et <span class="math inline">\(2\pi\)</span>-périodique.</p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>En réécrivant la densité spectrale, on a <span class="math display">\[\begin{eqnarray*}
f_X(\omega)
&amp;=&amp; \frac{1}{2\pi} \underset{h\in\Z}{\sum} \gamma_X(h) e^{-i\omega h}\\
&amp;=&amp; \frac{\gamma_X(0)}{2\pi} + \frac{1}{2\pi} \underset{h=-\infty}{\stackrel{-1}{\sum}} \gamma_X(h) e^{-i\omega h} + \frac{1}{2\pi} \underset{h=1}{\stackrel{+\infty}{\sum}} \gamma_X(h) e^{-i\omega h}\\
&amp;=&amp;\frac{\gamma_X(0)}{2\pi} + \frac{1}{2\pi} \underset{h=1}{\stackrel{+\infty}{\sum}} \gamma_X(h) \left(e^{-i\omega h}+ e^{i\omega h}\right)\\
&amp;=&amp;\frac{\gamma_X(0)}{2\pi} + \frac{1}{\pi} \underset{h=1}{\stackrel{+\infty}{\sum}} \gamma_X(h) \cos(\omega h)\\
\end{eqnarray*}\]</span> donc <span class="math inline">\(f_X(.)\)</span> est réelle, continue, paire et <span class="math inline">\(2\pi\)</span>-périodique.</p>
<p>Il reste à montrer que <span class="math inline">\(f_X(.)\)</span> est positive. Pour <span class="math inline">\(N\in\N\)</span>, on définit</p>
<span class="math display">\[\begin{eqnarray*}
f_N(\omega)
&amp;=&amp; = \frac{1}{2\pi N} \E\left[ \left|\underset{j=1}{\stackrel{N}{\sum}} (X_j - \mu_X) e^{-i\omega j}\right|^2 \right]\\
&amp;=&amp; \frac{1}{2\pi N}
\E\left[ \underset{j=1}{\stackrel{N}{\sum}} (X_j - \mu_X) e^{-i\omega j} \underset{k=1}{\stackrel{N}{\sum}} (X_k - \mu_X) e^{i\omega k} \right]\\
&amp;=&amp; \frac{1}{2\pi N}
\underset{j=1}{\stackrel{N}{\sum}}\underset{k=1}{\stackrel{N}{\sum}} e^{-i\omega (j-k)}
\E\left[  (X_j - \mu_X)(X_k - \mu_X)\right]\\
&amp;=&amp; \frac{1}{2\pi N}
\underset{j=1}{\stackrel{N}{\sum}}\underset{k=1}{\stackrel{N}{\sum}} e^{-i\omega (j-k)}
\gamma_X(j-k)\\
&amp;=&amp; \frac{1}{2\pi N}
\underset{h; |h|&lt;N}{\sum}\underset{j=|h|+1}{\stackrel{N}{\sum}} e^{-i\omega h} \gamma_X(h)\\
&amp;=&amp; \frac{1}{2\pi N}
\underset{h; |h|&lt;N}{\sum} (N-|h|) e^{-i\omega h} \gamma_X(h)\\
&amp;=&amp; \frac{1}{2\pi}
\underset{h; |h|&lt;N}{\sum} e^{-i\omega h} \gamma_X(h)
- \frac{1}{2\pi}
\underset{h; |h|&lt;N}{\sum} \frac{|h|}{N} e^{-i\omega h} \gamma_X(h).
\end{eqnarray*}\]</span>
<p>Comme <span class="math inline">\(\underset{h\in\Z}{\sum}|\gamma_X(h)|&lt;+\infty\)</span>, on a pour le premier terme que <span class="math display">\[
\frac{1}{2\pi}
\underset{h; |h|&lt;N}{\sum} e^{-i\omega h} \gamma_X(h) \underset{N\to +\infty}{\longrightarrow} \frac{1}{2\pi}
\underset{h\in\Z}{\sum} e^{-i\omega h} \gamma_X(h) = f_X(\omega).  
\]</span></p>
<p>Pour le second terme, on utilise le résultat suivant :</p>
<p>Soit <span class="math inline">\((a_h)_{h\in\Z}\)</span> une suite de réels positifs telle que <span class="math inline">\(\underset{h\in\Z}{\sum} a_h &lt; +\infty\)</span>. On a alors <span class="math display">\[
\underset{N\to +\infty}{\lim}  \underset{h; |h|&lt;N}{\sum} \frac{|h|}{N} a_h =0.
\]</span></p>
<p>Ici, on a <span class="math display">\[
0 \leq \left| \frac{1}{2\pi}
\underset{h; |h|&lt;N}{\sum} \frac{|h|}{N} e^{-i\omega h} \gamma_X(h)   \right| \leq \frac{1}{2\pi}
\underset{h; |h|&lt;N}{\sum} \frac{|h|}{N}  |\gamma_X(h)|
\underset{N\to +\infty}{\longrightarrow} 0.
\]</span></p>
<p>Au final, on a que <span class="math inline">\(f_N(\omega)\underset{N\to +\infty}{\longrightarrow} f_X(\omega),\ \forall \omega\in\R\)</span> et <span class="math inline">\(\forall \omega\in\R,\ f_N(\omega)\geq 0\)</span> ce qui conclut à la positivité de <span class="math inline">\(f_X(.)\)</span>.</p>
</div>
</div>
</div>
<div id="thm-caractdenspect" class="theoreme theorem">
<p><span class="theorem-title"><strong>Theorem 3.4 </strong></span>Il est équivalent de connaître la fonction d’autocovariance ou la densité spectrale, quand elle existe, d’un processus stationnaire <span class="math inline">\((X_t)_{t\in \Z}\)</span> :</p>
<p><span class="math display">\[
\gamma_X(h)=\int_{-\pi}^\pi f_X(\omega) \cos (\omega h )d\omega=\int_{-\pi}^\pi f_X(\omega) e^{i\omega h }d\omega.
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>On peut écrire : <span class="math display">\[\begin{eqnarray*}
\int_{-\pi}^\pi f_X(\omega) \cos (\omega h )d\omega
&amp;=&amp;\int_{-\pi}^\pi f_X(\omega) \left( \frac{e^{i\omega h}+e^{-i\omega h}}{2}\right)d\omega\\
&amp;=&amp;\frac{1}{2}\int_{-\pi}^\pi f_X(\omega)  e^{i\omega h}d\omega+\frac{1}{2}\int_{-\pi}^\pi f_X(\omega)  e^{-i\omega h}d\omega\\
&amp;=&amp;\int_{-\pi}^\pi f_X(\omega) e^{i\omega h }d\omega \ \ \ \text{par parité de la densité spectrale}\\
&amp;=&amp; \int_{-\pi}^\pi \frac{1}{2\pi}\sum_{k\in \Z}\gamma_X(k)e^{-i\omega k} e^{i\omega h }d\omega\\
&amp;=&amp;\frac{1}{2\pi}\sum_{k\in \Z}\gamma_X(k) \int_{-\pi}^\pi  e^{i\omega (h-k)}d\omega
\end{eqnarray*}\]</span> par la convergence normale de la série. Or</p>
<p><span class="math display">\[
\int_{-\pi}^\pi  e^{i\omega (h-k)}d\omega =
\left\{
\begin{array}{l l}
2\pi &amp; \textrm{ si } h=k\\
\\
\left[\frac{e^{i\omega(h-k)}}{h-k} \right]_{-\pi}^\pi=0 &amp; \text{ si } k\neq h
\end{array}
\right.
\]</span></p>
<p>Ainsi, <span class="math display">\[
\int_{-\pi}^\pi f_X(\omega) \cos (\omega h )d\omega=\gamma_X(h).
\]</span></p>
</div>
</div>
</div>
<div id="exm-denspectbb" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.7 (Bruit blanc faible) </strong></span>Soit un bruit blanc faible <span class="math inline">\((\varepsilon_t)_{t\in \Z}\sim \text{WN}(0,\sigma^2)\)</span>. Rappelons que sa fonction d’autocovariance vaut <span class="math inline">\(\gamma_\varepsilon(h) = \sigma^2 \mathbb{1}_{h=0}\)</span>. Sa densité spectrale vaut donc <span class="math display">\[
f_\varepsilon(\omega)=\frac{1}{2\pi}\sum_{h\in \Z}\gamma_\varepsilon(h)e^{-i\omega h}=\frac{\sigma^2}{2\pi},\ \forall \omega\in\R.
\]</span></p>
<p>Et réciproquement tout processus stationnaire de densité spectrale constante est un bruit blanc faible.</p>
</div>
<p>La proposition suivante concerne la densité spectrale d’un filtrage linéaire.</p>
<div id="prp-filtlindenspect" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.8 </strong></span><br> Soit <span class="math inline">\((X_t)_{t\in \Z}\)</span> un processus stationnaire de densité spectrale <span class="math inline">\(f_X(\cdot)\)</span>. Soit <span class="math inline">\((Y_t)_{t\in \Z}\)</span> un filtrage linéaire de la série <span class="math inline">\((X_t)_{t\in \Z}\)</span> défini par <span class="math display">\[
Y_t=\psi(B)X_t=\sum_{j=-\infty}^{+\infty}\psi_j X_{t-j}
\textrm{ avec }
\sum_{j=-\infty}^{+\infty}|\psi_j|&lt;+\infty.
\]</span> Le processus <span class="math inline">\((Y_t)_{t\in \Z}\)</span> est donc stationnaire de densité spectrale <span class="math display">\[
\forall \omega\in\R,\ f_Y(\omega)=f_X(\omega)\left|\sum_{j=-\infty}^{+\infty} \psi_j e^{-i\omega j}\right|^2.
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preuve
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Existence de la densité spectrale de <span class="math inline">\((Y_t)_{t\in\Z}\)</span>:</li>
</ul>
<p>Comme <span class="math inline">\(\sum_{j=-\infty}^{+\infty}|\psi_j|&lt;+\infty\)</span>, d’après la <a href="#prp-filtragelin">Proposition&nbsp;<span>3.5</span></a>, on a <span class="math display">\[
\gamma_Y(h) = \sum_{j\in\Z}\sum_{k\in\Z}\psi_j\psi_k\gamma_X(h+j-k).
\]</span></p>
<p>Donc <span class="math display">\[\begin{eqnarray*}
\sum_{h\in \Z} \left|\gamma_Y(h)\right|&amp;=&amp;\sum_{h\in \Z} \left| \sum_{j\in\Z}\sum_{k\in\Z}\psi_j\psi_k\gamma_X(h+j-k) \right|\\
&amp;\leq&amp;\sum_{h\in \Z} \sum_{j\in\Z}\sum_{k\in\Z} |\psi_j| |\psi_k| \left| \gamma_X(h+j-k) \right| \\
&amp;=&amp;\sum_{j\in\Z} |\psi_j| \cdot \sum_{k\in\Z} |\psi_k| \cdot \sum_{h\in \Z} \left| \gamma_X(h+j-k) \right|,
\end{eqnarray*}\]</span> où <span class="math inline">\(\sum_{h\in \Z} \left| \gamma_X(h+j-k) \right|&lt;+\infty\)</span> par hypothèse d’existence de la densité spectrale du processus <span class="math inline">\((X_t)_{t\in \Z}\)</span> et <span class="math inline">\(\sum_{j\in\Z} |\psi_j|&lt;+\infty\)</span> par hypothèse. Ainsi la densité spectrale du processus <span class="math inline">\((Y_t)_{t\in \Z}\)</span> existe d’après la <a href="#prp-existdenspect">Proposition&nbsp;<span>3.6</span></a>.</p>
<ul>
<li>Calcul de <span class="math inline">\(f_Y(.)\)</span> : Maintenant, on peut écrire <span class="math display">\[\begin{eqnarray*}
f_Y(\omega)
&amp;=&amp;\frac{1}{2\pi}\sum_{h\in \Z}\gamma_Y(h)e^{-i\omega h}\\
&amp;=&amp;\frac{1}{2\pi}\sum_{h\in \Z} \sum_{j\in\Z}\sum_{k\in\Z}\psi_j\psi_k\gamma_X(h+j-k) e^{-i\omega h}\\
&amp;=&amp;\frac{1}{2\pi}\sum_{j\in\Z} \psi_j e^{i\omega j}\sum_{k\in\Z}\psi_k e^{-i\omega k}\sum_{h\in \Z} \gamma_X(h+j-k)e^{-i\omega (h+j-k)}\\
&amp;=&amp;\frac{1}{2\pi}\left(\sum_{j\in\Z}\psi_j e^{i\omega j}\right)\left(\sum_{k\in\Z}\psi_k e^{-i\omega k} \right)\left(2\pi f_X(\omega) \right)\\
&amp;=&amp;f_X(\omega) \left|\sum_{j\in\Z} \psi_j e^{-i\omega j}\right|^2.
\end{eqnarray*}\]</span></li>
</ul>
</div>
</div>
</div>
<div id="exm-filtlindenspectbb" class="example theorem example">
<p><span class="theorem-title"><strong>Example 3.8 (Densité spectrale du filtrage linéaire d’un bruit blanc) </strong></span><br></p>
<p>Soit <span class="math inline">\((\varepsilon_t)_{t\in \Z}\sim \text{WN}(0,\sigma^2)\)</span> et <span class="math inline">\((Y_t)_{t\in \Z}\)</span> le filtrage linéaire de ce bruit blanc défini par <span class="math display">\[
    Y_t=\sum_{j\in \Z}\psi_j \varepsilon_{t-j}
\]</span> avec <span class="math inline">\(\sum_{j\in \Z}|\psi_j | &lt;+\infty\)</span>. D’après la <a href="#prp-filtlindenspect">Proposition&nbsp;<span>3.8</span></a>, la densité spectrale de ce processus est alors égale à : <span class="math display">\[
f_Y(\omega)=f_\varepsilon (\omega) \cdot \left|\sum_{j=-\infty}^{+\infty} \psi_j e^{-i\omega j}\right|^2=\frac{\sigma^2}{2\pi}\left|\sum_{j=-\infty}^{+\infty} \psi_j e^{-i\omega j}\right|^2.
\]</span></p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-aragon2016" class="csl-entry" role="listitem">
Aragon, Yves. 2016. <em>S<span>é</span>ries Temporelles Avec r</em>. EDP sciences.
</div>
<div id="ref-brockwell2002introduction" class="csl-entry" role="listitem">
Brockwell, Peter J, and Richard A Davis. 2002. <em>Introduction to Time Series and Forecasting</em>. Springer.
</div>
<div id="ref-brockwell2009time" class="csl-entry" role="listitem">
———. 2009. <em>Time Series: Theory and Methods</em>. Springer science &amp; business media.
</div>
<div id="ref-dauxois" class="csl-entry" role="listitem">
Dauxois, Jean-Yves. 2020. <span>“Introduction à l’étude Des Séries Temporelles.”</span> Polycopié cours INSA Toulouse.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chap1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Tendances et saisonnalités</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chap3.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Statistique des processus stationnaires du second ordre</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>